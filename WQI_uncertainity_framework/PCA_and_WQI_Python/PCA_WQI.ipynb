{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 2: Load your dataset directly from the current directory\n",
        "df = pd.read_excel('SPRINGS.xlsx')\n",
        "\n",
        "# Step 3: Select all numeric columns\n",
        "numeric_cols = df.select_dtypes(include=[np.number])\n",
        "\n",
        "# Step 4: Compute the correlation matrix\n",
        "corr_matrix = numeric_cols.corr()\n",
        "\n",
        "# Step 5: Display the correlation matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Step 6: Identify pairs of parameters with correlation above 0.9\n",
        "threshold = 0.9\n",
        "corr_pairs = corr_matrix.abs().unstack()\n",
        "high_corr = corr_pairs[(corr_pairs > threshold) & (corr_pairs < 1)].drop_duplicates()\n",
        "high_corr_pairs = high_corr.sort_values(ascending=False)\n",
        "\n",
        "print(\"Pairs of parameters with correlation above 0.9:\")\n",
        "for index, value in high_corr_pairs.items():\n",
        "    print(f\"{index[0]} and {index[1]}: correlation = {value:.2f}\")\n",
        "\n",
        "# Step 7: Save the correlation matrix to an Excel file\n",
        "corr_matrix.to_excel('correlation_before_SPRINGS_FG_PCA.xlsx')\n",
        "\n",
        "print(\"Correlation matrix saved to 'correlation_before.xlsx'\")\n",
        "# Manually drop the highly correlated parameters\n",
        "#example: dropping 'Conductivity at 20°C [µS/cm]' and 'Calcium [mg/l Ca]'' for my Srping dataset\n",
        "cols_to_drop = ['Conductivity at 20°C [µS/cm]', 'Calcium [mg/l Ca]']\n",
        "numeric_cols = numeric_cols.drop(columns=cols_to_drop)\n",
        "\n",
        "# Recompute the correlation matrix without the dropped parameters\n",
        "corr_matrix = numeric_cols.corr()\n",
        "\n",
        "# Display the new correlation matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix After Dropping Highly Correlated Parameters')\n",
        "plt.show()\n",
        "\n",
        "# Save the new correlation matrix to an Excel file\n",
        "corr_matrix.to_excel('correlation_after_SPRINGS.xlsx')\n",
        "\n",
        "print(\"Correlation matrix after dropping parameters saved to 'correlation_after.xlsx'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from factor_analyzer import calculate_kmo, calculate_bartlett_sphericity\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Use the numeric_cols dataframe from previous code, after dropping the columns\n",
        "\n",
        "# Handle missing values\n",
        "numeric_cols = numeric_cols.dropna()\n",
        "\n",
        "# Perform KMO test\n",
        "kmo_all, kmo_model = calculate_kmo(numeric_cols)\n",
        "print(f\"KMO Test Statistic: {kmo_model:.4f}\")\n",
        "\n",
        "# Perform Bartlett's Test\n",
        "chi_square_value, p_value = calculate_bartlett_sphericity(numeric_cols)\n",
        "print(f\"Bartlett's Test: Chi-square {chi_square_value:.4f}, p-value {p_value:.4f}\")\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(numeric_cols)\n",
        "\n",
        "# Run PCA\n",
        "pca = PCA()\n",
        "pca.fit(data_scaled)\n",
        "\n",
        "# Display PCA components with variance\n",
        "print(\"\\nExplained Variance Ratio of each Principal Component:\")\n",
        "for i, variance in enumerate(pca.explained_variance_ratio_):\n",
        "    print(f\"PC{i+1}: {variance:.4f}\")\n",
        "\n",
        "# Display eigenvalues\n",
        "eigenvalues = pca.explained_variance_\n",
        "print(\"\\nEigenvalues:\")\n",
        "for i, eigenvalue in enumerate(eigenvalues):\n",
        "    print(f\"PC{i+1}: {eigenvalue:.4f}\")\n",
        "\n",
        "# Save eigenvectors, eigenvalues, and explained variance to an Excel file\n",
        "components_df = pd.DataFrame(pca.components_, columns=numeric_cols.columns)\n",
        "components_df.index = [f\"PC{i+1}\" for i in range(len(components_df))]\n",
        "\n",
        "# Create a DataFrame for eigenvalues and explained variance\n",
        "eigenvalues_df = pd.DataFrame({\n",
        "    'Eigenvalue': pca.explained_variance_,\n",
        "    'Explained Variance Ratio': pca.explained_variance_ratio_\n",
        "})\n",
        "eigenvalues_df.index = [f\"PC{i+1}\" for i in range(len(eigenvalues_df))]\n",
        "\n",
        "# Write to Excel file with multiple sheets\n",
        "with pd.ExcelWriter('eigenvectors_eigenvalues_all_SPRINGS_FG_PCA.xlsx') as writer:\n",
        "    components_df.to_excel(writer, sheet_name='Eigenvectors')\n",
        "    eigenvalues_df.to_excel(writer, sheet_name='Eigenvalues')\n",
        "\n",
        "print(\"\\nEigenvectors, eigenvalues, and explained variance saved to 'eigenvectors_eigenvalues_all.xlsx'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from factor_analyzer import calculate_kmo, calculate_bartlett_sphericity\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Use the numeric_cols dataframe from previous code, after dropping the correlated parameters\n",
        "# Ensure 'numeric_cols' contains the data with dropped correlated parameters\n",
        "\n",
        "# Handle missing values\n",
        "numeric_cols = numeric_cols.dropna()\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(numeric_cols)\n",
        "\n",
        "# Specify the number of principal components to retain for example, 11 in this case\n",
        "n_components = 11\n",
        "\n",
        "# Run PCA with the specified number of components\n",
        "pca = PCA(n_components=n_components)\n",
        "pca.fit(data_scaled)\n",
        "\n",
        "# Display the retained explained variance ratio\n",
        "print(f\"\\nExplained Variance Ratio of the first {n_components} Principal Components:\")\n",
        "for i, variance in enumerate(pca.explained_variance_ratio_):\n",
        "    print(f\"PC{i+1}: {variance:.4f}\")\n",
        "\n",
        "# Display the retained eigenvalues\n",
        "eigenvalues = pca.explained_variance_\n",
        "print(f\"\\nEigenvalues of the first {n_components} Principal Components:\")\n",
        "for i, eigenvalue in enumerate(eigenvalues):\n",
        "    print(f\"PC{i+1}: {eigenvalue:.4f}\")\n",
        "\n",
        "# Save the retained eigenvectors to a DataFrame\n",
        "components_df = pd.DataFrame(pca.components_, columns=numeric_cols.columns)\n",
        "components_df.index = [f\"PC{i+1}\" for i in range(n_components)]\n",
        "\n",
        "# Create a DataFrame for the retained eigenvalues and explained variance\n",
        "eigenvalues_df = pd.DataFrame({\n",
        "    'Eigenvalue': eigenvalues,\n",
        "    'Explained Variance Ratio': pca.explained_variance_ratio_\n",
        "})\n",
        "eigenvalues_df.index = [f\"PC{i+1}\" for i in range(n_components)]\n",
        "\n",
        "# Define the function to calculate weights\n",
        "def calculate_weights_eq12a(pca, n_components):\n",
        "    \"\"\"\n",
        "    Calculates weights using eigenvectors and eigenvalues\n",
        "    wi = (Σ(sqrt(λj) × eij)) / Σλj\n",
        "    \"\"\"\n",
        "    eigenvalues = pca.explained_variance_[:n_components]\n",
        "    sum_eigenvalues = np.sum(eigenvalues)\n",
        "    eigenvectors = pca.components_[:n_components]\n",
        "\n",
        "    weights = []\n",
        "    for i in range(len(eigenvectors[0])):\n",
        "        vec_elements = eigenvectors[:, i]\n",
        "        weight = np.sum(np.sqrt(eigenvalues) * vec_elements) / sum_eigenvalues\n",
        "        weights.append(abs(weight))\n",
        "\n",
        "    weights_df = pd.DataFrame({\n",
        "        'Parameter': numeric_cols.columns,\n",
        "        'Weight': weights,\n",
        "        'Normalized Weight': weights / np.sum(weights)\n",
        "    }).sort_values('Normalized Weight', ascending=False)\n",
        "\n",
        "    return weights_df\n",
        "\n",
        "# Calculate weights using the function\n",
        "weights_df = calculate_weights_eq12a(pca, n_components)\n",
        "\n",
        "# Save all outputs to an Excel file with multiple sheets\n",
        "with pd.ExcelWriter('PCA_results_SPRINGS.xlsx') as writer:\n",
        "    components_df.to_excel(writer, sheet_name='Eigenvectors')\n",
        "    eigenvalues_df.to_excel(writer, sheet_name='Eigenvalues')\n",
        "    weights_df.to_excel(writer, sheet_name='Weights', index=False)\n",
        "\n",
        "print(\"\\nEigenvectors, eigenvalues, and weights saved to 'PCA_weights_springs.xlsx'\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
